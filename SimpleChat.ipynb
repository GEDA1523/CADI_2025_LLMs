{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67e9b1c7cdfc1ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e475e3d015d0dc",
   "metadata": {},
   "source": [
    "## Creación de un simple ChatBot que interactúa con llama 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee809484ba7879e",
   "metadata": {},
   "source": [
    "### 1. Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20561cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.9"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/pydantic/\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/1e/ab/45b180e175de4402dcf7547e4fb617283bae54ce35c27930a6f35b6bef15/charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core==0.3.21\n",
      "  Using cached langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-ollama==0.2.0\n",
      "  Using cached langchain_ollama-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain==0.3.9)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.9)\n",
      "  Using cached SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.3.9)\n",
      "  Downloading aiohttp-3.11.11-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.9)\n",
      "  Using cached langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.9)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain==0.3.9)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain==0.3.9)\n",
      "  Using cached pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting requests<3,>=2 (from langchain==0.3.9)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain==0.3.9)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.21)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\l01257675\\documents\\agosto-diciembre2021-dell\\ago-diciembre2024\\cadi2025\\cadi-llms\\cadi_2025_llms\\.venv\\lib\\site-packages (from langchain-core==0.3.21) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\l01257675\\documents\\agosto-diciembre2021-dell\\ago-diciembre2024\\cadi2025\\cadi-llms\\cadi_2025_llms\\.venv\\lib\\site-packages (from langchain-core==0.3.21) (4.12.2)\n",
      "Collecting ollama<1,>=0.3.0 (from langchain-ollama==0.2.0)\n",
      "  Using cached ollama-0.4.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Using cached attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core==0.3.21)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.9)\n",
      "  Downloading langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading orjson-3.10.12-cp311-none-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.9)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.9)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain==0.3.9)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain==0.3.9)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain==0.3.9)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain==0.3.9)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain==0.3.9)\n",
      "  Using cached greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Using cached anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting sniffio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Using cached langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "Using cached langchain_ollama-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading aiohttp-3.11.11-cp311-cp311-win_amd64.whl (442 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Using cached ollama-0.4.4-py3-none-any.whl (13 kB)\n",
      "Using cached pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 72.0 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 0.8/2.0 MB 136.4 kB/s eta 0:00:09\n",
      "   --------------- ------------------------ 0.8/2.0 MB 136.4 kB/s eta 0:00:09\n",
      "   --------------- ------------------------ 0.8/2.0 MB 136.4 kB/s eta 0:00:09\n",
      "   --------------------- ------------------ 1.0/2.0 MB 176.6 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 1.3/2.0 MB 225.9 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 1.8/2.0 MB 316.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 339.9 kB/s eta 0:00:00\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Using cached greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.12-cp311-none-win_amd64.whl (135 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "Using cached anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: urllib3, tenacity, sniffio, PyYAML, pydantic-core, propcache, orjson, numpy, multidict, jsonpointer, idna, h11, greenlet, frozenlist, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, httpx, aiohttp, ollama, langsmith, langchain-core, langchain-text-splitters, langchain-ollama, langchain\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.7.0 attrs-24.3.0 certifi-2024.12.14 charset-normalizer-3.4.1 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.9 langchain-core-0.3.21 langchain-ollama-0.2.0 langchain-text-splitters-0.3.2 langsmith-0.1.147 multidict-6.1.0 numpy-1.26.4 ollama-0.4.4 orjson-3.10.12 propcache-0.2.1 pydantic-2.10.4 pydantic-core-2.27.2 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 urllib3-2.3.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.3.9 langchain-core==0.3.21 langchain-ollama==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d2707c728a2d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:50:56.686095Z",
     "start_time": "2024-11-21T19:50:56.060193Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf26fb11c3b0d",
   "metadata": {},
   "source": [
    "## 2. Large language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab209c5e57c5d3",
   "metadata": {},
   "source": [
    "Hay diferentes modelos que se pueden usar. La mayoría necesita un \"API KEY\":\n",
    "\n",
    "ChatOpenAI, ChatAnthropic, ChatVertexAI, ChatCohere, ChatNVIDIA, ChatGroq, ChatMistralAI\n",
    "\n",
    "Existen otros modelos en la plataforma HUGGINGFACE.\n",
    "\n",
    "Para la mayoría de los modelos hay que definir una variable de entorno:\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "import getpass\n",
    "\n",
    "import os\n",
    "\n",
    "export OPENAI_API_KEY=\"...\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "Usando Ollama en local no es necesario definir variables de entorno. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:51:29.667040Z",
     "start_time": "2024-11-21T19:51:29.646351Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_llm = 'llama3'\n",
    "llm = ChatOllama(model=local_llm, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca09143b4658d2",
   "metadata": {},
   "source": [
    "Algunos de los parámetros más importantes que se deben/pueden especificar:\n",
    "\n",
    "-**model**: el nombre del modelo específico que se quiere usar (por ejemplo, para ChatOpenAI puede ser \"gpt-3.5-turbo\" o \"gpt-4\")\n",
    "\n",
    "**temperature**: controla la aleatoriedad de la respuesta (y la capacidad \"generativa\"), el valor mínimo es 0 (muy baja aleatoriedad y creatividad).\n",
    "\n",
    "**timeout**: el máximo tiempo de espera para obtener la respuesta\n",
    "\n",
    "**max_tokens**: es un número que limita el valor máximo de palabra y puntuación en la respuesta.\n",
    "\n",
    "**api_key**: el api key del usuario\n",
    "\n",
    "No todos los modelos admiten los mismos parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc276cd940e2d89e",
   "metadata": {},
   "source": [
    "Métodos clave del modelo de chat:\n",
    "\n",
    "-**invoke**: El método principal para interactuar con un modelo de chat. Acepta una lista de mensajes como entrada y devuelve una lista de mensajes como salida.\n",
    "\n",
    "-**stream**: Un método que permite transmitir la salida de un modelo de chat a medida que se genera.\n",
    "\n",
    "-**batch**: Un método que permite agrupar varias solicitudes a un modelo de chat para su procesamiento eficiente.\n",
    "\n",
    "-**bind_tools**: Un método que permite vincular una herramienta a un modelo de chat para su uso en el contexto de ejecución del modelo.\n",
    "\n",
    "-**with_structured_output**: Un envoltorio alrededor del método invoke para modelos que admiten natively salida estructurada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb68249f90d9421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:56:11.458246Z",
     "start_time": "2024-11-21T19:56:06.271833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¡Hola! translates to \"Hello!\" in English.', additional_kwargs={}, response_metadata={'model': 'llama3', 'created_at': '2024-12-27T21:45:52.6163226Z', 'done': True, 'done_reason': 'stop', 'total_duration': 25700781000, 'load_duration': 12679356000, 'prompt_eval_count': 20, 'prompt_eval_duration': 5015000000, 'eval_count': 12, 'eval_duration': 7942000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a985ff4f-926f-4aef-9281-7282751f1459-0', usage_metadata={'input_tokens': 20, 'output_tokens': 12, 'total_tokens': 32})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages= 'Hola, traduce al inglés: hola'\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b84ad75b25a89",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6c4a70a22679655",
   "metadata": {},
   "source": [
    "### 3. Mensajes\n",
    "\n",
    "Un mensaje suele consistir en las siguientes piezas de información:\n",
    "\n",
    "-**Rol**: El rol del mensaje (por ejemplo, \"usuario\", \"asistente\").\n",
    "\n",
    "-**Contenido**: El contenido del mensaje (por ejemplo, texto, datos multimodales).\n",
    "\n",
    "-**Metadatos adicionales**: id, nombre, uso de tokens y otros metadatos específicos del modelo.\n",
    "\n",
    "Rol\n",
    "Los roles se utilizan para distinguir entre diferentes tipos de mensajes en una conversación y ayudar al modelo de chat a entender cómo responder a una secuencia determinada de mensajes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e7721f8ee3daea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:59:40.630742Z",
     "start_time": "2024-11-21T19:59:40.627809Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from english to spanish\"),\n",
    "    HumanMessage(content=\"Hi\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b40ea6efd755e7",
   "metadata": {},
   "source": [
    "Se puede usar un \"parser\" para escribir la respuesta sin metedatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e856039318cc1f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:01:04.397393Z",
     "start_time": "2024-11-21T20:01:03.205263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = StrOutputParser()\n",
    "result = llm.invoke(messages)\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8226eaac7f614b7",
   "metadata": {},
   "source": [
    "Se pueden juntar el modelo y el parser en una \"chain\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e77666759cdde8df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:01:25.164581Z",
     "start_time": "2024-11-21T20:01:24.358762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8417bbf15244e2f6",
   "metadata": {},
   "source": [
    "**Temperature**\n",
    "\n",
    "Repetimos 5 veces la pregunta \"Escribe un color cualquiera\" y analizamos las respuestas para diferentes valores del parámetro \"temperature\". Para un valor de temperature=0:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88a691e0fd7d8349",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:13:24.537977Z",
     "start_time": "2024-11-21T20:13:18.876665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El color que te voy a escribir es... **azul**.\n",
      "El color que te voy a escribir es... **azul**.\n",
      "El color que te voy a escribir es... **azul**.\n",
      "El color que te voy a escribir es... **azul**.\n",
      "El color que te voy a escribir es... **azul**.\n"
     ]
    }
   ],
   "source": [
    "messages = 'Hola, escribe un color cualquiera'\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "chain = llm | parser\n",
    "for i in range(5):\n",
    "    print(chain.invoke(messages))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e6899eab795f",
   "metadata": {},
   "source": [
    "Para el valor temperature=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e78d574fa7e94211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:14:35.435018Z",
     "start_time": "2024-11-21T20:14:26.332131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azul.\n",
      "Turquesa.\n",
      "El color que te voy a escribir es... **azul**.\n",
      "**Tuspa**\n",
      "\n",
      "Un color vibrante y emotivo que evoca una sensación de energía y creatividad.\n",
      "**Rojo**\n",
      "\n",
      "¿Te gusta el rojo? Es uno de los colores más vibrantes y emocionales que hay en el espectro visible. El rojo es una combinación perfecta de energía y pasión, y suele asociarse con sentimientos fuertes como el amor, la intensidad y la creatividad.\n",
      "\n",
      "¿Quieres saber más sobre el significado del color rojo o tienes alguna pregunta relacionada?\n"
     ]
    }
   ],
   "source": [
    "messages = 'Hola, escribe un color cualquiera\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1)\n",
    "chain = llm | parser\n",
    "for i in range(5):\n",
    "    print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648613d13e4eb6db",
   "metadata": {},
   "source": [
    "**top-k y top-P**\n",
    "\n",
    "Al igual que la temperatura, los parámetros top-K y top-P también se utilizan para controlar la diversidad de la salida del modelo.\n",
    "\n",
    "Top-K es un número entero positivo que define la cantidad de tokens más probables de los cuales seleccionar el token de salida. Un top-K de 1 selecciona un solo token.\n",
    "\n",
    "Top-P define el umbral de probabilidad que, una vez excedido de forma acumulativa, los tokens dejan de ser seleccionados como candidatos. Un top-P de 0 es equivalente típicamente al top K con k=1, y un top-P de 1 selecciona típicamente todos los tokens en el vocabulario del modelo.\n",
    "\n",
    "Ejecute este ejemplo varias veces, cambie la configuración y observe el cambio en la salida.\n",
    " \n",
    "- top k =64  top_p = 0.95\n",
    "\n",
    "- top k=1 top_p =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "520ba039b748d467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:26:17.419229Z",
     "start_time": "2024-11-21T20:25:42.739272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Whispering Woods**\n",
      "\n",
      "Whiskers, the curious cat, stood at the threshold of her cozy home, paw on the doorframe, as if hesitating to leave. Her tail twitched with excitement and caution, like two antennae tuning into the whispers of the universe. The moon cast a silver glow outside, illuminating the windowsill where the morning sunlight had left its mark.\n",
      "\n",
      "Without warning, Whiskers sprang from the comfort of her doorstep, tail in tow, as if swept by an unseen force. She padded silently across the porch and vanished into the heart of the Whispering Woods.\n",
      "\n",
      "The forest was alive with the secrets it kept within its ancient boughs and whispering leaves. The air vibrated with whispers – murmurs from creatures great and small – each sharing tales of long-forgotten deeds, love stories, and mysteries veiled in mist. Whiskers followed the siren's call, her ears perked up like satellite dishes tuning into a hidden frequency.\n",
      "\n",
      "As she wandered deeper, the trees grew taller and closer together, their branches intertwined above her head. Shafts of moonlight broke through the canopy, casting dappled shadows on the forest floor. Whiskers navigated with an air of feline confidence, though every now and then, she'd pause to listen and inhale.\n",
      "\n",
      "She stumbled upon a clearing where creatures from dreams gathered. A great stag stood sentinel, his antlers shining in moonlight, while a fox, once mortal, now a shape-shifter's friend, danced alongside a tiny fairy no bigger than Whiskers' paw. They welcomed her with whispers of gratitude and shared tales of their adventures.\n",
      "\n",
      "A breeze rustled the leaves as a fabled cat appeared before her – Purrfectia, an ancient matriarch whose whiskers held secrets of the past and eyes that shone like stars on moonlit nights. The elder cat regarded Whiskers, as if sizing up the fledgling's bravery.\n",
      "\n",
      "Whiskers stood poised, ears erect, sensing a gateway to knowledge hidden within these whispers and stories. Without needing words, Purrfectia shared with a mere touch of her whisker that this forest held an ancient secret – the one hidden path that led beyond mortal limits. The feline companion gifted Whiskers a whispered password: _Echoes of Eternity_.\n",
      "\n",
      "Within seconds, Whiskers felt transformed, as if the whispers had imbued her with secrets of old. Her eyes now shone like moonlit shadows on stone walls, knowing she was bound to keep these whispers hidden – sharing them when they were needed by those brave enough to search.\n",
      "\n",
      "When dawn crept over the horizon, painting the forest in hues of sunrise and golden twilight, Whiskers padded back to her doorstep, silent as a ghost. As if awakening from a dream, she stepped onto the porch, looked around curiously, then took a moment to smile.\n",
      "\n",
      "Her home beckoned once more, but now her heart was no longer whole – only half-satisfied by what lay hidden within Whispering Woods and the secrets shared with her as an honored guest of the unknown.\n"
     ]
    }
   ],
   "source": [
    "messages = \"You are a creative writer. Write a short story about a cat who goes on an adventure\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1, top_k=64,\n",
    "        top_p=0.95)\n",
    "chain = llm | parser\n",
    "print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c29fb6084bd0966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:27:29.516198Z",
     "start_time": "2024-11-21T20:26:39.268207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Whiskered Wanderer**\n",
      "\n",
      "In the sleepy town of Willowdale, where sunbeams danced through the windows and dust motes waltzed in the air, a sleek black cat named Midnight prowled the streets. Her eyes gleamed like polished onyx as she padded silently from house to house, searching for adventure.\n",
      "\n",
      "Midnight's owner, an elderly lady named Mrs. Jenkins, had grown fond of her mischievous ways and often left treats and toys scattered about the house. But tonight, Midnight yearned for something more – a taste of freedom, a dash of excitement.\n",
      "\n",
      "As she slipped out into the night air, the world came alive around her. Fireflies twinkled like tiny lanterns, casting a magical glow over the cobblestone streets. The scent of blooming flowers wafted on the breeze, enticing Midnight to explore further.\n",
      "\n",
      "She padded through alleys and side streets, weaving past sleeping dogs and snoring cats. Her ears perked up at every sound – a chirping cricket, a hooting owl, or the distant rumble of thunder. With each step, Midnight felt her whiskers twitching with anticipation.\n",
      "\n",
      "As she wandered deeper into the town, Midnight stumbled upon a hidden path she had never seen before. The air grew thick with the scent of damp earth and moss, and the trees seemed to lean in, as if sharing a secret. Without hesitation, Midnight followed the winding trail, her paws padding softly on the forest floor.\n",
      "\n",
      "The trees grew taller and closer together here, casting dappled shadows across the ground. Midnight's eyes adjusted to the dim light, and she spotted a glint of silver in the distance – a small stream, its surface reflecting the starry sky above.\n",
      "\n",
      "Without hesitation, Midnight plunged into the water, sending ripples through the calm surface. She paddled with her front paws, feeling the cool liquid envelop her fur. As she swam, the world around her dissolved into a kaleidoscope of colors and sounds – the chirping of crickets, the rustling of leaves, and the gentle lapping of water against her ears.\n",
      "\n",
      "For a moment, Midnight forgot about Mrs. Jenkins, the treats, and the comforts of home. She was free, untethered by the constraints of everyday life. The stream became her own personal highway, carrying her to unknown destinations and hidden wonders.\n",
      "\n",
      "As she swam further downstream, Midnight spotted a family of otters playing in the shallows. They welcomed her with open arms – or rather, open paws – and invited her to join their game of chase-the-fish. Midnight laughed, a throaty purr rumbling deep within her chest, as she chased after the slippery creatures.\n",
      "\n",
      "Eventually, the sun began to rise, casting a golden glow over the forest. Midnight reluctantly bid farewell to her new friends and continued downstream, following the stream until it merged with a larger river.\n",
      "\n",
      "As she emerged from the water, shaking off excess droplets, Midnight spotted a majestic castle rising above the trees – its towers reaching for the clouds like giant's fists. The wind whispered secrets in her ear, and Midnight felt an inexplicable pull towards the ancient structure.\n",
      "\n",
      "Without hesitation, she padded up the winding path, her tail twitching with excitement. As she reached the entrance, a pair of stone lions gazed down at her, their eyes gleaming with a knowing intelligence. Midnight pushed open the massive doors, and a warm light spilled out, bathing her in its radiance.\n",
      "\n",
      "Inside, she discovered a labyrinthine library filled with ancient tomes and mysterious artifacts. The air was thick with the scent of parchment and knowledge. Midnight's whiskers twitched as she explored the shelves, uncovering secrets hidden within the pages of forgotten books.\n",
      "\n",
      "As the sun climbed higher in the sky, casting long shadows across the castle walls, Midnight realized it was time to return home. She bid farewell to the library, promising to keep its secrets safe, and began her journey back through the forest.\n",
      "\n",
      "The stream had changed course overnight, but Midnight navigated its twists and turns with ease, guided by the memories of her adventure. As she emerged from the trees, Mrs. Jenkins welcomed her with open arms, a warm smile on her face.\n",
      "\n",
      "\"Midnight, where have you been?\" she asked, scratching behind the cat's ears.\n",
      "\n",
      "Midnight purred contentedly, her eyes gleaming with a secret knowledge. She knew that some adventures were meant to remain hidden, but others – like this one – would stay with her forever, etched in the whispers of her whiskers and the beat of her heart.\n"
     ]
    }
   ],
   "source": [
    "messages = \"You are a creative writer. Write a short story about a cat who goes on an adventure\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1, top_k=1,\n",
    "        top_p=0)\n",
    "chain = llm | parser\n",
    "print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7d135ca719b6130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:30:45.480944Z",
     "start_time": "2024-11-21T20:29:54.503023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Whiskered Wanderer**\n",
      "\n",
      "In the sleepy town of Willowdale, where sunbeams danced through the windows and dust motes waltzed in the air, a sleek black cat named Midnight prowled the streets. Her eyes gleamed like polished onyx as she padded silently from house to house, searching for adventure.\n",
      "\n",
      "Midnight's owner, an elderly lady named Mrs. Jenkins, had grown fond of her mischievous ways and often left treats and toys scattered about the house. But tonight, Midnight yearned for something more – a taste of freedom, a dash of excitement.\n",
      "\n",
      "As she slipped out into the night air, the world came alive around her. Fireflies twinkled like tiny lanterns, casting a magical glow over the cobblestone streets. The scent of blooming flowers wafted on the breeze, enticing Midnight to explore further.\n",
      "\n",
      "She padded through alleys and side streets, weaving past sleeping dogs and snoring cats. Her ears perked up at every sound – a chirping cricket, a hooting owl, or the distant rumble of thunder. With each step, Midnight felt her whiskers twitching with anticipation.\n",
      "\n",
      "As she wandered deeper into the town, Midnight stumbled upon a hidden path she had never seen before. The air grew thick with the scent of damp earth and moss, and the trees seemed to lean in, as if sharing a secret. Without hesitation, Midnight followed the winding trail, her paws padding softly on the forest floor.\n",
      "\n",
      "The trees grew taller and closer together here, casting dappled shadows across the ground. Midnight's eyes adjusted to the dim light, and she spotted a glint of silver in the distance – a small stream, its surface reflecting the starry sky above.\n",
      "\n",
      "Without hesitation, Midnight plunged into the water, sending ripples through the calm surface. She paddled with her front paws, feeling the cool liquid envelop her fur. As she swam, the world around her dissolved into a kaleidoscope of colors and sounds – the chirping of crickets, the rustling of leaves, and the gentle lapping of water against her ears.\n",
      "\n",
      "For a moment, Midnight forgot about Mrs. Jenkins, the treats, and the comforts of home. She was free, untethered by the constraints of everyday life. The stream became her own personal highway, carrying her to unknown destinations and hidden wonders.\n",
      "\n",
      "As she swam further downstream, Midnight spotted a family of otters playing in the shallows. They welcomed her with open arms – or rather, open paws – and invited her to join their game of chase-the-fish. Midnight laughed, a throaty purr rumbling deep within her chest, as she chased after the slippery creatures.\n",
      "\n",
      "Eventually, the sun began to rise, casting a golden glow over the forest. Midnight reluctantly bid farewell to her new friends and continued downstream, following the stream until it merged with a larger river.\n",
      "\n",
      "As she emerged from the water, shaking off excess droplets, Midnight spotted a majestic castle rising above the trees – its towers reaching for the clouds like giant's fists. The wind whispered secrets in her ear, and Midnight felt an inexplicable pull towards the ancient structure.\n",
      "\n",
      "Without hesitation, she padded up the winding path, her tail twitching with excitement. As she reached the entrance, a pair of stone lions gazed down at her, their eyes gleaming with a knowing intelligence. Midnight pushed open the massive doors, and a warm light spilled out, bathing her in its radiance.\n",
      "\n",
      "Inside, she discovered a labyrinthine library filled with ancient tomes and mysterious artifacts. The air was thick with the scent of parchment and knowledge. Midnight's whiskers twitched as she explored the shelves, uncovering secrets hidden within the pages of forgotten books.\n",
      "\n",
      "As the sun climbed higher in the sky, casting long shadows across the castle walls, Midnight realized it was time to return home. She bid farewell to the library, promising to keep its secrets safe, and began her journey back through the forest.\n",
      "\n",
      "The stream had changed course overnight, but Midnight navigated its twists and turns with ease, guided by the memories of her adventure. As she emerged from the trees, Mrs. Jenkins welcomed her with open arms, a warm smile on her face.\n",
      "\n",
      "\"Midnight, where have you been?\" she asked, scratching behind the cat's ears.\n",
      "\n",
      "Midnight purred contentedly, her eyes gleaming with a secret knowledge. She knew that some adventures were meant to remain hidden, but others – like this one – would stay with her forever, etched in the whispers of her whiskers and the beat of her heart.\n"
     ]
    }
   ],
   "source": [
    "messages = \"You are a creative writer. Write a short story about a cat who goes on an adventure\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1, top_k=5,\n",
    "        top_p=0)\n",
    "chain = llm | parser\n",
    "print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feecf481711e508",
   "metadata": {},
   "source": [
    "## 2. Prompt templates\n",
    "\n",
    "Si se quieren hacer preguntas siempre del mismo tipo, dando las mismas instrucciones al sustema, se pueden definir \"prompt templates\", que pueden contener variables, definidas entre {}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8328963faa7b4f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:05:13.245816Z",
     "start_time": "2024-11-21T20:05:13.242267Z"
    }
   },
   "outputs": [],
   "source": [
    "system_template = \"Translate the following into {language}, write only the translated word:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7997d3031ff3b160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:20.103655Z",
     "start_time": "2024-11-21T20:53:20.100003Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "931e2e513973b3a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:21.633014Z",
     "start_time": "2024-11-21T20:53:21.618308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian, write only the translated word:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3782042470db8cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:25.711320Z",
     "start_time": "2024-11-21T20:53:25.706511Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fb8794710829214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:32.121166Z",
     "start_time": "2024-11-21T20:53:27.501663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84ee819fef100606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:47.718716Z",
     "start_time": "2024-11-21T20:53:45.841225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "chain.invoke({\"topic\": \"cats\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2854038925b328",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
